{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-07T14:34:24.089652Z",
     "iopub.status.busy": "2021-12-07T14:34:24.089229Z",
     "iopub.status.idle": "2021-12-07T14:34:31.614197Z",
     "shell.execute_reply": "2021-12-07T14:34:31.612972Z",
     "shell.execute_reply.started": "2021-12-07T14:34:24.089547Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n",
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:32: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ._gradient_boosting import predict_stages\n",
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:32: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ._gradient_boosting import predict_stages\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "from scipy import sparse\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Raw Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T14:34:31.616915Z",
     "iopub.status.busy": "2021-12-07T14:34:31.616321Z",
     "iopub.status.idle": "2021-12-07T14:34:31.990034Z",
     "shell.execute_reply": "2021-12-07T14:34:31.989418Z",
     "shell.execute_reply.started": "2021-12-07T14:34:31.616856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6421, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>States reported 1121 deaths a small rise from ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Populous states can generate large case counts...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet label\n",
       "0   1  The CDC currently reports 99031 deaths. In gen...  real\n",
       "1   2  States reported 1121 deaths a small rise from ...  real\n",
       "2   3  Politically Correct Woman (Almost) Uses Pandem...  fake\n",
       "3   4  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
       "4   5  Populous states can generate large case counts...  real"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "data = pd.read_csv('data.tsv', sep='\\t')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "# Removing punctuations\n",
    "data['tweet']= data['tweet'].apply(lambda x:remove_punctuation(x))\n",
    "\n",
    "\n",
    "# Converting text into lower case\n",
    "data['tweet']= data['tweet'].apply(lambda x: x.lower())\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = text.split(\" \")\n",
    "    output= \" \".join([i for i in text if i not in stopwords])\n",
    "    return output\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Removing stopwords\n",
    "for i in range(len(data)):\n",
    "    data[\"tweet\"][i] = remove_stopwords(data[\"tweet\"][i])\n",
    "    \n",
    "\n",
    "# Removing urls.....\n",
    "for i in range(len(data)):\n",
    "    temp = data[\"tweet\"][i].split(\" \")\n",
    "    if temp[-1].startswith(\"http\"):\n",
    "        temp.pop()\n",
    "    data[\"tweet\"][i] = \" \".join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>cdc currently reports 99031 deaths general dis...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>states reported 1121 deaths small rise last tu...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>politically correct woman almost uses pandemic...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>indiafightscorona 1524 covid testing laborator...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>populous states generate large case counts loo...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet label\n",
       "0   1  cdc currently reports 99031 deaths general dis...  real\n",
       "1   2  states reported 1121 deaths small rise last tu...  real\n",
       "2   3  politically correct woman almost uses pandemic...  fake\n",
       "3   4  indiafightscorona 1524 covid testing laborator...  real\n",
       "4   5  populous states generate large case counts loo...  real"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6416</td>\n",
       "      <td>6417</td>\n",
       "      <td>autopsies prove covid19 is� blood clot pneumon...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6417</td>\n",
       "      <td>6418</td>\n",
       "      <td>post claims covid19 vaccine already developed ...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6418</td>\n",
       "      <td>6419</td>\n",
       "      <td>aamir khan donate 250 cr pm relief cares fund</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6419</td>\n",
       "      <td>6420</td>\n",
       "      <td>93 days since last case covid19 acquired local...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6420</td>\n",
       "      <td>6421</td>\n",
       "      <td>house democratic caucus holds moment silence 1...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              tweet label\n",
       "6416  6417  autopsies prove covid19 is� blood clot pneumon...  fake\n",
       "6417  6418  post claims covid19 vaccine already developed ...  fake\n",
       "6418  6419      aamir khan donate 250 cr pm relief cares fund  fake\n",
       "6419  6420  93 days since last case covid19 acquired local...  real\n",
       "6420  6421  house democratic caucus holds moment silence 1...  real"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['tweet']\n",
    "y = data['label']\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T14:34:36.608487Z",
     "iopub.status.busy": "2021-12-07T14:34:36.60724Z",
     "iopub.status.idle": "2021-12-07T14:34:36.672192Z",
     "shell.execute_reply": "2021-12-07T14:34:36.671188Z",
     "shell.execute_reply.started": "2021-12-07T14:34:36.608411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real    2693\n",
      "fake    2443\n",
      "Name: label, dtype: int64\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "# train_x, test_x, train_y, test_y = model_selection.train_test_split(trainDF['question'], trainDF['main_category'], test_size=0.2, random_state=42)\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "print(train_y.value_counts())\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "test_y = encoder.fit_transform(test_y)\n",
    "\n",
    "classes = list(encoder.classes_)\n",
    "print(len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T14:34:39.610743Z",
     "iopub.status.busy": "2021-12-07T14:34:39.61044Z",
     "iopub.status.idle": "2021-12-07T14:34:39.616872Z",
     "shell.execute_reply": "2021-12-07T14:34:39.615908Z",
     "shell.execute_reply.started": "2021-12-07T14:34:39.610712Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "\n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    \n",
    "    acc = metrics.accuracy_score(predictions, test_y)\n",
    "    f1 = metrics.f1_score(predictions, test_y, average='weighted')\n",
    "    #print(classification_report(predictions, test_y, target_names = list(encoder.classes_)))\n",
    "    return acc, f1, classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T07:32:24.568282Z",
     "iopub.status.busy": "2021-12-07T07:32:24.567924Z",
     "iopub.status.idle": "2021-12-07T07:32:27.062011Z",
     "shell.execute_reply": "2021-12-07T07:32:27.060963Z",
     "shell.execute_reply.started": "2021-12-07T07:32:24.568227Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5136, 14624), (1285, 14624))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(x)\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.fit_transform(train_x)\n",
    "xvalid_count =  count_vect.transform(test_x)\n",
    "xtrain_count.shape, xvalid_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T08:58:18.440943Z",
     "iopub.status.busy": "2021-12-07T08:58:18.439364Z",
     "iopub.status.idle": "2021-12-07T10:04:57.779822Z",
     "shell.execute_reply": "2021-12-07T10:04:57.778522Z",
     "shell.execute_reply.started": "2021-12-07T08:58:18.440794Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, Count Vectors: \n",
      "\n",
      "Accuracy Score: 0.5198443579766537\n",
      "f1 Score: 0.6840757808499744\n",
      "Wall time: 13.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SVM on Count Vectors\n",
    "accuracy, f1, classifier = train_model(svm.SVC(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"SVM, Count Vectors: \\n\")\n",
    "print(\"Accuracy Score: {}\".format(accuracy))\n",
    "print(\"f1 Score: {}\".format(f1))\n",
    "\n",
    "# Save the model to output folder\n",
    "filename = 'count_vec.pkl'\n",
    "with open(filename, 'wb') as fp:\n",
    "    pickle.dump(classifier, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5198443579766537\n",
      "0.6840757808499744\n"
     ]
    }
   ],
   "source": [
    "with open('./count_vec.pkl', 'rb') as file_1:\n",
    "    clf_1 = pickle.load(file_1)\n",
    "predictions = clf_1.predict(xvalid_count)\n",
    "acc = metrics.accuracy_score(predictions, test_y)\n",
    "f1 = metrics.f1_score(predictions, test_y, average='weighted')\n",
    "print(acc)\n",
    "print(f1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Level TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T10:39:40.88446Z",
     "iopub.status.busy": "2021-12-07T10:39:40.88416Z",
     "iopub.status.idle": "2021-12-07T10:39:43.185031Z",
     "shell.execute_reply": "2021-12-07T10:39:43.184188Z",
     "shell.execute_reply.started": "2021-12-07T10:39:40.884428Z"
    }
   },
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern = r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(x)\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T10:40:46.736056Z",
     "iopub.status.busy": "2021-12-07T10:40:46.735777Z",
     "iopub.status.idle": "2021-12-07T11:24:01.790844Z",
     "shell.execute_reply": "2021-12-07T11:24:01.789953Z",
     "shell.execute_reply.started": "2021-12-07T10:40:46.736027Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, TF-IDF Vectors: \n",
      "\n",
      "Accuracy Score: 0.5198443579766537\n",
      "f1 Score: 0.6840757808499744\n",
      "Wall time: 12.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SVM on TF IDF Vectors\n",
    "accuracy, f1, classifier = train_model(svm.SVC(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"SVM, TF-IDF Vectors: \\n\")\n",
    "print(\"Accuracy Score: {}\".format(accuracy))\n",
    "print(\"f1 Score: {}\".format(f1))\n",
    "\n",
    "# Save the model to output folder\n",
    "filename = 'word-tfidf.pkl'\n",
    "with open(filename, 'wb') as fp:\n",
    "    pickle.dump(classifier, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5198443579766537\n",
      "0.6840757808499744\n"
     ]
    }
   ],
   "source": [
    "with open('./word-tfidf.pkl', 'rb') as file_2:\n",
    "    clf_2 = pickle.load(file_2)\n",
    "predictions = clf_2.predict(xvalid_tfidf)\n",
    "acc = metrics.accuracy_score(predictions, test_y)\n",
    "f1 = metrics.f1_score(predictions, test_y, average='weighted')\n",
    "print(acc)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ngram Word Level TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T11:29:49.244589Z",
     "iopub.status.busy": "2021-12-07T11:29:49.244315Z",
     "iopub.status.idle": "2021-12-07T11:29:58.995952Z",
     "shell.execute_reply": "2021-12-07T11:29:58.995286Z",
     "shell.execute_reply.started": "2021-12-07T11:29:49.24456Z"
    }
   },
   "outputs": [],
   "source": [
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', ngram_range=(2,3), max_features=25000)\n",
    "tfidf_vect_ngram.fit(x)\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T11:31:28.275708Z",
     "iopub.status.busy": "2021-12-07T11:31:28.27544Z",
     "iopub.status.idle": "2021-12-07T12:19:13.04378Z",
     "shell.execute_reply": "2021-12-07T12:19:13.042693Z",
     "shell.execute_reply.started": "2021-12-07T11:31:28.27568Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, Ngram Level Vectors: \n",
      "\n",
      "Accuracy Score: 0.5198443579766537\n",
      "f1 Score: 0.6840757808499744\n",
      "Wall time: 8.68 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SVM on Ngram Level TF IDF Vectors\n",
    "accuracy, f1, classifier = train_model(svm.SVC(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "# print(\"SVM, Ngram Level Vectors: \", accuracy, f1)\n",
    "print(\"SVM, Ngram Level Vectors: \\n\")\n",
    "print(\"Accuracy Score: {}\".format(accuracy))\n",
    "print(\"f1 Score: {}\".format(f1))\n",
    "\n",
    "# Save the model to output folder\n",
    "filename = 'ngram-tfidf.pkl'\n",
    "with open(filename, 'wb') as fp:\n",
    "    pickle.dump(classifier, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5198443579766537\n",
      "0.6840757808499744\n"
     ]
    }
   ],
   "source": [
    "with open('ngram-tfidf.pkl', 'rb') as fp:\n",
    "    classifier_ = pickle.load(fp)\n",
    "predictions = classifier_.predict(xvalid_tfidf_ngram)\n",
    "acc = metrics.accuracy_score(predictions, test_y)\n",
    "f1 = metrics.f1_score(predictions, test_y, average='weighted')\n",
    "print(acc)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Char Level TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T14:34:46.907319Z",
     "iopub.status.busy": "2021-12-07T14:34:46.906965Z",
     "iopub.status.idle": "2021-12-07T14:35:00.711312Z",
     "shell.execute_reply": "2021-12-07T14:35:00.71041Z",
     "shell.execute_reply.started": "2021-12-07T14:34:46.907278Z"
    }
   },
   "outputs": [],
   "source": [
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', ngram_range=(2,3), max_features=25000)\n",
    "tfidf_vect_ngram_chars.fit(x)\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
    "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(test_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T14:35:59.20796Z",
     "iopub.status.busy": "2021-12-07T14:35:59.207648Z",
     "iopub.status.idle": "2021-12-07T18:45:16.502872Z",
     "shell.execute_reply": "2021-12-07T18:45:16.500454Z",
     "shell.execute_reply.started": "2021-12-07T14:35:59.207929Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, Character Level Vectors: \n",
      "\n",
      "Accuracy Score: 0.5198443579766537\n",
      "f1 Score: 0.6840757808499744\n",
      "Wall time: 1min 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KiranDon\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SVM on Character Level TF IDF Vectors\n",
    "accuracy, f1, classifier = train_model(svm.SVC(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "# print(\"SVM, Character Level Vectors: \", accuracy, f1)\n",
    "print(\"SVM, Character Level Vectors: \\n\")\n",
    "print(\"Accuracy Score: {}\".format(accuracy))\n",
    "print(\"f1 Score: {}\".format(f1))\n",
    "\n",
    "\n",
    "# Save the model to output folder\n",
    "filename = 'char-tfidf.pkl'\n",
    "with open(filename, 'wb') as fp:\n",
    "    pickle.dump(classifier, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5198443579766537\n",
      "0.6840757808499744\n"
     ]
    }
   ],
   "source": [
    "with open('./char-tfidf.pkl', 'rb') as fp:\n",
    "    classifier_ = pickle.load(fp)\n",
    "predictions = classifier_.predict(xvalid_tfidf_ngram_chars)\n",
    "acc = metrics.accuracy_score(predictions, test_y)\n",
    "f1 = metrics.f1_score(predictions, test_y, average='weighted')\n",
    "print(acc)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real\n"
     ]
    }
   ],
   "source": [
    "# tweet = [\"An old family friend died from #COVID__19 today. At a hospital in Denver. Because Amarillo hospitals had no room. \"]\n",
    "# tweet = [\"The CDC currently reports 99031 deaths. In general the discrepancies in death counts between different sources are small and explicable. The death toll stands at roughly 100000 people today.\"]\n",
    "tweet = [\"India has successfully vaccinated all of its population.\"]\n",
    "# tweet = [\"China president xi jinping visited masjid and request Muslims for dua in present crisis country going through.we need your help.\"]\n",
    "# tweet = [\"Scientists at AstraZeneca complain their work on a coronavirus vaccine keeps being delayed by Noddy Holder ringing up to ask if it will be ready by Christmas\"]\n",
    "chars =  tfidf_vect_ngram_chars.transform(tweet)\n",
    "result = classifier_.predict(chars)[0]\n",
    "if result==0:\n",
    "    print(\"Fake\")\n",
    "else:\n",
    "    print(\"Real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
